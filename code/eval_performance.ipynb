{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from test_setup import problems\n",
    "\n",
    "\n",
    "def plot_pf_d2(problem_name, problem, seed_ind_data):\n",
    "    true_pf = problem._calc_pareto_front().T\n",
    "    fig1 = px.line(x=true_pf[0], y=true_pf[1])\n",
    "    fig1.update_traces(\n",
    "        line=dict(color = 'rgba(50,50,50,0.4)'))\n",
    "\n",
    "    #seed_ind_data = seed_ind_data[seed_ind_data.problem_name == problem_name]\n",
    "    d2_seed_types_to_plot = [\"e1\", \"e2\", \"c\"]\n",
    "    seed_ind_data = seed_ind_data[seed_ind_data.type.isin(d2_seed_types_to_plot)]\n",
    "    fig2 = px.scatter(seed_ind_data, x=\"obj_1\", y=\"obj_2\", color=\"type\")\n",
    "    fig2.update_traces(marker_size = 9)\n",
    "\n",
    "    fig3 = go.Figure(data=fig1.data + fig2.data)\n",
    "    fig3.update_layout(\n",
    "        autosize=False,\n",
    "        margin=dict(\n",
    "            l=0,  # left margin\n",
    "            r=0,  # right margin\n",
    "            b=0,  # bottom margin\n",
    "            t=40,  # top margin\n",
    "            pad=0  # padding\n",
    "        ),\n",
    "        height=300,\n",
    "        width=375, #to make d2 and d3 the same size\n",
    "        title=problem_name,\n",
    "        xaxis_title=\"f1\",\n",
    "        yaxis_title=\"f2\",\n",
    "        font_size=12,\n",
    "    )\n",
    "\n",
    "    pareto_set_F = problem._calc_pareto_front(n_pareto_points=3)\n",
    "    upper_bounds = pareto_set_F.max(axis=0) \n",
    "    lower_bounds = pareto_set_F.min(axis=0)\n",
    "\n",
    "    #center\n",
    "    fig3.add_shape(\n",
    "            type=\"line\",\n",
    "            x0=lower_bounds[0],\n",
    "            y0=lower_bounds[1],\n",
    "            x1=upper_bounds[0]*0.39, #0.39 to make the vector cut off at the right point\n",
    "            y1=upper_bounds[1]*0.39,\n",
    "            line=dict(\n",
    "                color=px.colors.qualitative.Plotly[2],\n",
    "                width=4,\n",
    "                dash=\"dot\",\n",
    "            ),\n",
    "            label=dict(text=\"vector c\")\n",
    "    )\n",
    "    print(px.colors.qualitative.Plotly)\n",
    "    #edge 2\n",
    "    fig3.add_shape(\n",
    "            type=\"line\",\n",
    "            x0=lower_bounds[0],\n",
    "            y0=lower_bounds[1],\n",
    "            x1=upper_bounds[0],\n",
    "            y1=lower_bounds[1],\n",
    "            line=dict(\n",
    "                color=px.colors.qualitative.Plotly[1],\n",
    "                width=4,\n",
    "                dash=\"dot\",\n",
    "            ),\n",
    "            label=dict(text=\"vector e2\")\n",
    "    )\n",
    "\n",
    "    #edge 1\n",
    "    fig3.add_shape(\n",
    "            type=\"line\",\n",
    "            x0=lower_bounds[0],\n",
    "            y0=lower_bounds[1],\n",
    "            x1=lower_bounds[0],\n",
    "            y1=upper_bounds[1],\n",
    "            line=dict(\n",
    "                color=px.colors.qualitative.Plotly[0],\n",
    "                width=4,\n",
    "                dash=\"dot\",\n",
    "            ),\n",
    "            label=dict(text=\"vector e1\")\n",
    "    )\n",
    "\n",
    "    fig3.write_image(\"../figures/paper/seed_ind_generation_\"+problem_name+\".pdf\")\n",
    "    fig3.show()\n",
    "\n",
    "\n",
    "def plot_pf_d3(problem_name, problem, seed_ind_data):\n",
    "    true_pf = problem._calc_pareto_front(n_pareto_points=625).T\n",
    "    fig1 = px.scatter_3d(x=true_pf[0], y=true_pf[1], z=true_pf[2])\n",
    "    fig1.update_traces(marker=dict(\n",
    "        color = 'rgba(50,50,50,0.4)'),\n",
    "        marker_size = 6)\n",
    "\n",
    "    #seed_ind_data = seed_ind_data[seed_ind_data.problem_name == problem_name]\n",
    "    d3_seed_types_to_plot = [\"e1\", \"e2\", \"e3\", \"c\"]\n",
    "    seed_ind_data = seed_ind_data[seed_ind_data.type.isin(d3_seed_types_to_plot)]\n",
    "    fig2 = px.scatter_3d(seed_ind_data, x=\"obj_1\", y=\"obj_2\", z=\"obj_3\", color=\"type\")\n",
    "\n",
    "\n",
    "    name = 'eye = (x:2, y:2, z:2)'\n",
    "    camera = dict(\n",
    "        eye=dict(x=1.1, y=1.1, z=1.6)\n",
    "    )\n",
    "\n",
    "    fig3 = go.Figure(data=fig2.data + fig1.data)\n",
    "    fig3.update_layout(\n",
    "        scene_camera=camera,\n",
    "        autosize=False,\n",
    "        margin=dict(\n",
    "            l=0,  # left margin\n",
    "            r=0,  # right margin\n",
    "            b=00,  # bottom margin\n",
    "            t=40,  # top margin\n",
    "            pad=0  # padding\n",
    "        ),\n",
    "        height=400,\n",
    "        width=500,\n",
    "        title=problem_name,\n",
    "        font_size=16,\n",
    "        scene=dict(\n",
    "            xaxis_title=\"f1\",\n",
    "            yaxis_title=\"f2\",\n",
    "            zaxis_title=\"f3\",\n",
    "        ),\n",
    "    )\n",
    "    fig3.write_image(\"../figures/paper/seed_ind_generation_\"+problem_name+\".pdf\")\n",
    "    fig3.show()\n",
    "\n",
    "\n",
    "for problem_name in problems.keys():\n",
    "    problem = problems[problem_name]\n",
    "    fitness_data = pd.read_csv(\"../data/seed_individuals/seed_individuals_\"+problem_name+\".csv\")\n",
    "    if problem_name == \"UF1\": #problem.n_obj == 2: #only plot Maco and DTLZ1\n",
    "        plot_pf_d2(problem_name, problem, fitness_data)\n",
    "    if problem_name == \"UF8\": #problem.n_obj == 3:\n",
    "        plot_pf_d3(problem_name, problem, fitness_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Performance Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "baseline_comparison_d2 = pd.read_csv(\"../data/e_and_c_benchmark/baseline_comparison_data_d2.csv.tar.gz\")\n",
    "baseline_comparison_d2 = baseline_comparison_d2.loc[baseline_comparison_d2.generation == 100]\n",
    "baseline_comparison_d2 = baseline_comparison_d2.loc[(baseline_comparison_d2.problem_name != \"ZDT4\") & (baseline_comparison_d2.problem_name != \"ZDT6\") & (baseline_comparison_d2.problem_name != \"MACO_w=shallow\")]#filter unused problems\n",
    "baseline_comparison_d3 = pd.read_csv(\"../data/e_and_c_benchmark/baseline_comparison_data_d3.csv.tar.gz\")\n",
    "baseline_comparison_d3 = baseline_comparison_d3.loc[baseline_comparison_d3.generation == 100]\n",
    "\n",
    "baseline_comparison_d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partial_table(performance_indicator, algorithm, dataframe):\n",
    "    current_df = dataframe.loc[dataframe.algorithm == algorithm]\n",
    "    results_df = pd.DataFrame(columns=current_df.problem_name.unique(), index=current_df.seed_type.unique(), dtype=str)\n",
    "    for problem_name in current_df.problem_name.unique():\n",
    "        for seed_type in current_df.seed_type.unique():\n",
    "            results_df[problem_name][seed_type] = current_df.loc[(current_df.problem_name == problem_name) & (current_df.seed_type == seed_type)].iloc[0][performance_indicator]\n",
    "    return results_df\n",
    "\n",
    "def build_table(data, dim):\n",
    "    performance_indicators = [\"average_igd+_text\", \"average_hv_text\"]\n",
    "    algorithms=data.algorithm.unique()\n",
    "\n",
    "    single_solution_performance_indicator = []\n",
    "    for performance_indicator in performance_indicators:\n",
    "        single_res_palgorithm = []\n",
    "        for algorithm in algorithms:\n",
    "            single_res_palgorithm.append( get_partial_table(performance_indicator, algorithm, data) )\n",
    "        results_df = pd.concat(single_res_palgorithm, keys=algorithms)\n",
    "        single_solution_performance_indicator.append(results_df)\n",
    "    df_concat = pd.concat(single_solution_performance_indicator,axis=1,keys=performance_indicators)\n",
    "\n",
    "    latex_string = df_concat.to_latex(multicolumn=True, multirow=True, escape=False)\n",
    "    latex_string = latex_string.replace(\"\\\\multirow[t]\", \"\\\\multirow[c]\")#center the multirow\n",
    "    latex_string = latex_string.replace(\"{r}\", \"{c}\")#center the multicol\n",
    "    latex_string = latex_string.replace(\"_text\", \"\")#remove this lable from the performance indicator\n",
    "    latex_string = latex_string.replace(\"_\", \" \")#center the multirow\n",
    "    latex_string = latex_string.replace(\"llllllllllllllllllll\", \"p{0.44cm}p{0.44cm}|p{0.44cm}p{0.44cm}p{0.44cm}p{0.44cm}p{0.44cm}p{0.44cm}p{0.44cm}p{0.44cm}p{0.44cm}||p{0.44cm}p{0.44cm}p{0.44cm}p{0.44cm}p{0.44cm}p{0.44cm}p{0.44cm}p{0.44cm}p{0.44cm}\")#center the multirow d2\n",
    "    latex_string = latex_string.replace(\"llllllllllllll\", \"p{0.5cm}p{0.8cm}|p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}||p{0.5cm}p{0.5cm}p{0.66cm}p{0.5cm}p{0.5cm}p{0.8cm}\")#center the multirow d3\n",
    "    with open(\"../figures/paper/performance_comparison/performance_comparison_table_d\"+str(dim)+\".tex\", \"w\") as text_file:\n",
    "        text_file.write(latex_string)\n",
    "\n",
    "table_d2_df = baseline_comparison_d2[[\"problem_name\", \"algorithm\", \"seed_type\", \"average_igd+_text\", \"percentual_igd+_diff_text\", \"average_hv_text\", \"percentual_hv_diff_text\"]]\n",
    "table_d3_df = baseline_comparison_d3[[\"problem_name\", \"algorithm\", \"seed_type\", \"average_igd+_text\", \"percentual_igd+_diff_text\", \"average_hv_text\", \"percentual_hv_diff_text\"]]\n",
    "\n",
    "build_table(table_d2_df, 2)\n",
    "build_table(table_d3_df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heiner Gedächnis Table (unused)\n",
    "\n",
    "table_d2_df = baseline_comparison_d2[[\"problem_name\", \"algorithm\", \"seed_type\", \"average_igd+\", \"percentual_igd+_diff_text\", \"average_hv\", \"percentual_hv_diff_text\"]]\n",
    "\n",
    "# post-process the latex string\n",
    "latex_string = table_d2_df.to_latex(index=False, sparsify=True, multicolumn=True, multirow=True, escape=False)\n",
    "latex_string = latex_string.replace(\"\\\\multirow[t]\", \"\\\\multirow[c]\")#center the multirow\n",
    "latex_string = latex_string.replace(\"{r}\", \"{c}\")#center the multicol\n",
    "#latex_string = latex_string.replace(\"best\", \"b\")#shorten the row names\n",
    "#latex_string = latex_string.replace(\"lower quartile\", \"lq\")\n",
    "latex_string = latex_string.replace(\"seed_type\", \"seed type\")\n",
    "latex_string = latex_string.replace(\"average_igd+\", \"igd+\")\n",
    "latex_string = latex_string.replace(\"percentual_igd+_diff_text\", \"igd+ diff\")\n",
    "latex_string = latex_string.replace(\"average_hv\", \"hv\")\n",
    "latex_string = latex_string.replace(\"percentual_hv_diff_text\", \"hv diff\")\n",
    "latex_string = latex_string.replace(\"problem_name\", \"problem\")\n",
    "latex_string = latex_string.replace(\"_\", \"\\_\") #for the MACO_b\n",
    "latex_string = latex_string.replace(\"lllrlrl\", \"ccc||cc||cc\")# insert hlines\n",
    "\n",
    "#write the file\n",
    "with open(\"../figures/paper/performance_comparison/performance_comparison_table_d2.tex\", \"w\") as text_file:\n",
    "    text_file.write(latex_string)\n",
    "\n",
    "\n",
    "\n",
    "table_d3_df = baseline_comparison_d3[[\"problem_name\", \"algorithm\", \"seed_type\", \"average_igd+\", \"percentual_igd+_diff_text\", \"average_hv\", \"percentual_hv_diff_text\"]]\n",
    "\n",
    "# post-process the latex string\n",
    "latex_string = table_d3_df.to_latex(index=False, sparsify=True, multicolumn=True, multirow=True, escape=False)\n",
    "latex_string = latex_string.replace(\"seed_type\", \"seed type\")\n",
    "latex_string = latex_string.replace(\"average_igd+\", \"igd+\")\n",
    "latex_string = latex_string.replace(\"percentual_igd+_diff_text\", \"igd+ diff\")\n",
    "latex_string = latex_string.replace(\"average_hv\", \"hv\")\n",
    "latex_string = latex_string.replace(\"percentual_hv_diff_text\", \"hv diff\")\n",
    "latex_string = latex_string.replace(\"problem_name\", \"problem\")\n",
    "latex_string = latex_string.replace(\"_\", \"\\_\") #for the MACO_b\n",
    "latex_string = latex_string.replace(\"lllrlrl\", \"ccc||cc||cc\")# insert hlines\n",
    "\n",
    "with open(\"../figures/paper/performance_comparison/performance_comparison_table_d3.tex\", \"w\") as text_file:\n",
    "    text_file.write(latex_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing with Random as Baseline / Average Performance Indicator Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "baseline_comparison_d2 = pd.read_csv(\"../data/e_and_c_benchmark/baseline_comparison_data_d2.csv\")\n",
    "baseline_comparison_d2 = baseline_comparison_d2.loc[baseline_comparison_d2.generation == 100]\n",
    "baseline_comparison_d2 = baseline_comparison_d2.loc[(baseline_comparison_d2.problem_name != \"ZDT4\") & (baseline_comparison_d2.problem_name != \"ZDT6\") & (baseline_comparison_d2.problem_name != \"MACO_w=shallow\")]#filter unused problems\n",
    "baseline_comparison_d3 = pd.read_csv(\"../data/e_and_c_benchmark/baseline_comparison_data_d3.csv\")\n",
    "baseline_comparison_d3 = baseline_comparison_d3.loc[baseline_comparison_d3.generation == 100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmaps of the percentual difference\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "def plot_heatmap(dataframe, indicator_name, dim):\n",
    "    algorithm_names = dataframe.algorithm.unique()\n",
    "    fig = make_subplots(cols=1, rows=len(algorithm_names), shared_xaxes=True, x_title=indicator_name,\n",
    "                        horizontal_spacing = 0.001,\n",
    "                        vertical_spacing = 0.066,\n",
    "                        row_titles=[\"NSGA-II\", \"MOEA/D\"])#, row_titles=algorithm_names, start_cell=\"top-left\")\n",
    "\n",
    "    dataframe = dataframe.replace(to_replace=\"e1+e2\",value=\"e1+2\") #rename the seed types for better readability\n",
    "    dataframe = dataframe.replace(to_replace=\"e1+e2+e3\",value=\"e1+2+3\")\n",
    "    dataframe = dataframe.replace(to_replace=\"e1+e2+c\",value=\"e1+2+c\")\n",
    "    dataframe = dataframe.replace(to_replace=\"e1+e2+e3+c\",value=\"e1+2+3+c\")\n",
    "    for i, algorithm_name in enumerate(algorithm_names):\n",
    "        plot_data = dataframe.loc[(dataframe['seed_type'] != 'r') & (dataframe['algorithm'] == algorithm_name)]\n",
    "        fig.add_trace(go.Heatmap(\n",
    "            z=plot_data[indicator_name],\n",
    "            zmid=0.0,\n",
    "            zmin=-1.0,\n",
    "            zmax=1.0,\n",
    "            x=plot_data['problem_name'],\n",
    "            y=plot_data['seed_type'],\n",
    "            text=plot_data[indicator_name+\"_text\"],\n",
    "            texttemplate=\"%{text}\",\n",
    "            textfont={\"size\":11},\n",
    "            colorscale='RdBu',\n",
    "            colorbar=dict(title=\"Relative<br>IGD+ Diff\")),\n",
    "            col=1, row=i+1,\n",
    "        )\n",
    "        # Update x-axis and y-axis labels\n",
    "    if dim == 2:#this is bodged, but only update the 2D MACO problem names\n",
    "        fig.update_xaxes(tickvals=[\"MACO_b\", \"MACO_p=-10\", \"MACO_w=steep\", \"UF1\", \"UF2\", \"UF3\", \"ZDT1\", \"ZDT2\", \"ZDT3\"],\n",
    "                        ticktext=[\"MACO<br>b\", \"MACO<br>p=-10\", \"MACO<br>w=steep\", \"UF1\", \"UF2\", \"UF3\", \"ZDT1\", \"ZDT2\", \"ZDT3\"])\n",
    "    #fig.update_yaxes(tickvals=[\"MACO_b\"], ticktext=[\"MACO \\n b\"])\n",
    "    fig.update_layout(\n",
    "        height=350,\n",
    "        #width=150*len(filtered_df.problem_name.unique()),\n",
    "        margin=dict(l=0, r=0, t=25, b=0),\n",
    "        font=dict(size=13)\n",
    "    )\n",
    "    fig.write_image(\"../figures/paper/performance_comparison/roi_\"+indicator_name+\"_d\"+str(dim)+\".pdf\")\n",
    "    fig.show()\n",
    "\n",
    "plot_heatmap(baseline_comparison_d2, \"percentual_gd_diff\", dim=2)\n",
    "plot_heatmap(baseline_comparison_d3, \"percentual_gd_diff\", dim=3)\n",
    "\n",
    "plot_heatmap(baseline_comparison_d2, \"percentual_igd+_diff\", dim=2)\n",
    "plot_heatmap(baseline_comparison_d3, \"percentual_igd+_diff\", dim=3)\n",
    "\n",
    "plot_heatmap(baseline_comparison_d2, \"percentual_hv_diff\", dim=2)\n",
    "plot_heatmap(baseline_comparison_d3, \"percentual_hv_diff\", dim=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the PFs found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fitness_d2 = pd.read_csv(\"../data/e_and_c_benchmark/fitness_and_ranks_do2_gen100.csv.tar.gz\")\n",
    "fitness_d2 = fitness_d2.loc[(fitness_d2.problem_name != \"ZDT4\") & (fitness_d2.problem_name != \"ZDT6\") & (fitness_d2.problem_name != \"MACO_w=shallow\")]#filter unused problems\n",
    "fitness_d2 = fitness_d2.loc[fitness_d2.goldberg_rank == 0]\n",
    "\n",
    "fitness_d3 = pd.read_csv(\"../data/e_and_c_benchmark/fitness_and_ranks_do3_gen100.csv.tar.gz\")\n",
    "fitness_d3 = fitness_d3.loc[fitness_d3.goldberg_rank == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some helper methods\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def get_2d_scatterplot(data, seedID) -> go.scatter:\n",
    "    return go.Scatter(\n",
    "            x=data[\"f_1\"],\n",
    "            y=data[\"f_2\"],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                color=data[seedID],\n",
    "                colorscale=px.colors.sequential.algae,\n",
    "                colorbar=dict(thickness=20, bordercolor='white', title=\"Impact\"),\n",
    "                cmin=0,\n",
    "                cmax=1,\n",
    "                opacity=0.5\n",
    "            ),\n",
    "            showlegend=False,\n",
    "        )\n",
    "\n",
    "def get_2d_pf_fig(problem) -> go.scatter:\n",
    "    pf = problem._calc_pareto_front()\n",
    "    return go.Scatter(\n",
    "                x=pf[:, 0],\n",
    "                y=pf[:, 1],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=3, color=\"grey\"),\n",
    "                showlegend=False\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def plot_2d_data(data, problem_name):\n",
    "    data = data[data.problem_name == problem_name]\n",
    "    data = data.drop(columns=[\"problem_name\"])\n",
    "\n",
    "    fig = px.scatter(\n",
    "        data,\n",
    "        x=\"f_1\",\n",
    "        y=\"f_2\",\n",
    "        facet_col=\"seed_type\",\n",
    "        facet_row=\"algorithm_name\",\n",
    "        #color=\"seed_type\",\n",
    "        title=problem_name,\n",
    "        labels={\n",
    "            \"traceID_1\": \"Impact\"\n",
    "        },\n",
    "        facet_col_spacing=0.0,\n",
    "        facet_row_spacing=0.0\n",
    "    )\n",
    "\n",
    "\n",
    "    #add PF plot to each sub plot\n",
    "    for j in range(1, len(data['seed_type'].unique())+1):#rows\n",
    "        for i in range(1, len(data['algorithm_name'].unique())+1):#cols\n",
    "            fig.add_trace(get_2d_pf_fig(problems[problem_name]), row=i, col=j)\n",
    "    fig.update_layout(title=problem_name, height=400, width=1100,\n",
    "        margin=dict(l=0, r=0, t=25, b=0),\n",
    "    )\n",
    "    fig.for_each_annotation(lambda a: a.update( text=a.text.removeprefix(\"seed_type=\") ))#remove the prefix\n",
    "    fig.for_each_annotation(lambda a: a.update( text=a.text.removeprefix(\"algorithm_name=\") ))#remove the prefix\n",
    "    fig.write_image(\"../figures/test/pareto_fronts/single_seed_pf_\"+problem_name+\".pdf\")\n",
    "\n",
    "\n",
    "data = fitness_d2[[\"generation\", \"f_1\", \"f_2\", \"problem_name\", \"algorithm_name\", \"seed_type\"]]\n",
    "#data = data[(data.seed_type == \"e1\") | (data.seed_type == \"e2\") | (data.seed_type == \"c\")]\n",
    "problem_names = data.problem_name.unique()\n",
    "for problem_name in problem_names:\n",
    "    plot_2d_data(data, problem_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def get_3d_scatterplot(data, seedID) -> go.scatter3d:\n",
    "    return go.Scatter3d(\n",
    "            x=data[\"f_1\"],\n",
    "            y=data[\"f_2\"],\n",
    "            z=data[\"f_3\"],\n",
    "            mode=\"markers\",\n",
    "            showlegend=False,\n",
    "        )\n",
    "\n",
    "def get_3d_pf_fig(problem) -> go.scatter3d:\n",
    "    pf = problem._calc_pareto_front()\n",
    "    return go.Scatter3d(\n",
    "                x=pf[:, 0],\n",
    "                y=pf[:, 1],\n",
    "                z=pf[:, 2],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=3, color=\"grey\"),\n",
    "                showlegend=False\n",
    "            )\n",
    "\n",
    "\n",
    "#The scene camera:\n",
    "camera = dict(\n",
    "    up=dict(x=0, y=0, z=1),\n",
    "    center=dict(x=0, y=0, z=0),\n",
    "    eye=dict(x=1.5, y=1.5, z=1.5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all of the 3d one seed data\n",
    "from test_setup import problems\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def plot_3d_data(data, problem_name, algorithm_name):\n",
    "    data = data[data.algorithm_name == algorithm_name]\n",
    "    data = data[data.problem_name == problem_name]\n",
    "    data = data.drop(columns=[\"problem_name\"])\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1,\n",
    "        cols=7,\n",
    "        subplot_titles=(\"r\", \"e1\", \"e2\", \"e3\", \"c\", \"e1+e2+e3\", \"e1+e2+e3+c\"),\n",
    "        start_cell=\"top-left\",\n",
    "        specs=[\n",
    "            [{\"type\": \"scatter3d\"}, {\"type\": \"scatter3d\"}, {\"type\": \"scatter3d\"}, {\"type\": \"scatter3d\"}, {\"type\": \"scatter3d\"}, {\"type\": \"scatter3d\"}, {\"type\": \"scatter3d\"}],\n",
    "        ],\n",
    "        horizontal_spacing = 0.01\n",
    "    )\n",
    "\n",
    "    for i, seed_type in enumerate(data.seed_type.unique()): #columns\n",
    "        fig.update_scenes(\n",
    "            camera=camera,\n",
    "            row=1, col=i+1\n",
    "        )\n",
    "        fig.add_trace(get_3d_scatterplot(data[data.seed_type == seed_type], \"traceID_1\"), row=1, col=i+1)\n",
    "        fig.add_trace(get_3d_pf_fig(problems[problem_name]), row=1, col=i+1) #add the true PF\n",
    "        \n",
    "    fig.update_layout(title=problem_name+\" \"+algorithm_name, height=400, width=1600,\n",
    "        margin=dict(l=0, r=0, t=35, b=0),\n",
    "    )\n",
    "\n",
    "    fig.write_image(\"../figures/test/pareto_fronts/single_seed_pf_\"+problem_name+\"_\"+algorithm_name+\".pdf\")\n",
    "\n",
    "data = fitness_d3[[\"generation\", \"f_1\", \"f_2\", \"f_3\", \"problem_name\", \"algorithm_name\", \"seed_type\"]]\n",
    "problem_names = data.problem_name.unique()\n",
    "for problem_name in problem_names:\n",
    "    plot_3d_data(data, problem_name, \"NSGA2\")\n",
    "    plot_3d_data(data, problem_name, \"MOEAD\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line Plot Average Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "baseline_comparison_d2 = pd.read_csv(\"../data/e_and_c_benchmark/baseline_comparison_data_d2.csv.tar.gz\")\n",
    "baseline_comparison_d3 = pd.read_csv(\"../data/e_and_c_benchmark/baseline_comparison_data_d3.csv.tar.gz\")\n",
    "\n",
    "baseline_comparison_d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def line_plot_average(dataframe, performance_indicator, problem_family, log_y=True):\n",
    "    fig = px.line(\n",
    "        dataframe.loc[(dataframe.problem_name.str.contains(problem_family))],\n",
    "        x=\"generation\",\n",
    "        y=performance_indicator,\n",
    "        color=\"seed_type\",\n",
    "        facet_col=\"problem_name\",\n",
    "        facet_row=\"algorithm\",\n",
    "        title=performance_indicator+\" \"+problem_family,\n",
    "        log_y=log_y\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "#igd+\n",
    "# line_plot_average(baseline_comparison_d3, \"average_igd+\", \"DTLZ\")\n",
    "# line_plot_average(baseline_comparison_d3, \"average_igd+\", \"UF\")\n",
    "# line_plot_average(baseline_comparison_d2, \"average_igd+\", \"ZDT\")\n",
    "# line_plot_average(baseline_comparison_d2, \"average_igd+\", \"UF\")\n",
    "line_plot_average(baseline_comparison_d2, \"average_igd+\", \"MACO\")\n",
    "\n",
    "#gd\n",
    "# line_plot_average(baseline_comparison_d3, \"average_gd\", \"DTLZ\")\n",
    "# line_plot_average(baseline_comparison_d3, \"average_gd\", \"UF\")\n",
    "# line_plot_average(baseline_comparison_d2, \"average_gd\", \"ZDT\")\n",
    "# line_plot_average(baseline_comparison_d2, \"average_gd\", \"UF\")\n",
    "# line_plot_average(baseline_comparison_d2, \"average_gd\", \"MACO\")\n",
    "\n",
    "# #hv\n",
    "# line_plot_average(baseline_comparison_d3, \"average_hv\", \"DTLZ\")\n",
    "# line_plot_average(baseline_comparison_d3, \"average_hv\", \"UF\")\n",
    "# line_plot_average(baseline_comparison_d2, \"average_hv\", \"ZDT\")\n",
    "# line_plot_average(baseline_comparison_d2, \"average_hv\", \"UF\")\n",
    "# line_plot_average(baseline_comparison_d2, \"average_hv\", \"MACO\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Final Generation Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "performance_indicators_d2 = pd.read_csv(\"../data/e_and_c_benchmark/performance_indicators_do2_plus_HV.csv\")\n",
    "performance_indicators_d2 = performance_indicators_d2.loc[performance_indicators_d2.generation == performance_indicators_d2.generation.max()]\n",
    "performance_indicators_d3 = pd.read_csv(\"../data/e_and_c_benchmark/performance_indicators_do3_plus_HV.csv\")\n",
    "performance_indicators_d3 = performance_indicators_d3.loc[performance_indicators_d3.generation == performance_indicators_d3.generation.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def line_plot_average(dataframe, performance_indicator, problem_family):\n",
    "    fig = px.box(\n",
    "        dataframe.loc[(dataframe.problem_name.str.contains(problem_family))],\n",
    "        x=\"seed_type\",\n",
    "        y=performance_indicator,\n",
    "        color=\"seed_type\",\n",
    "        facet_col=\"problem_name\",\n",
    "        facet_row=\"algorithm_name\",\n",
    "        title=performance_indicator+\" \"+problem_family,\n",
    "        log_y=True\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "#igd+\n",
    "# line_plot_average(performance_indicators_d3, \"igd+\", \"DTLZ\")\n",
    "# line_plot_average(performance_indicators_d3, \"igd+\", \"UF\")\n",
    "# line_plot_average(performance_indicators_d2, \"igd+\", \"ZDT\")\n",
    "line_plot_average(performance_indicators_d2, \"igd+\", \"UF\")\n",
    "line_plot_average(performance_indicators_d2, \"igd+\", \"MACO\")\n",
    "\n",
    "#gd\n",
    "# line_plot_average(performance_indicators_d3, \"gd\", \"DTLZ\")\n",
    "# line_plot_average(performance_indicators_d3, \"gd\", \"UF\")\n",
    "# line_plot_average(performance_indicators_d2, \"gd\", \"ZDT\")\n",
    "# line_plot_average(performance_indicators_d2, \"gd\", \"UF\")\n",
    "# line_plot_average(performance_indicators_d2, \"gd\", \"MACO\")\n",
    "\n",
    "#hv\n",
    "# line_plot_average(performance_indicators_d3, \"hv\", \"DTLZ\")\n",
    "# line_plot_average(performance_indicators_d3, \"hv\", \"UF\")\n",
    "# line_plot_average(performance_indicators_d2, \"hv\", \"ZDT\")\n",
    "# line_plot_average(performance_indicators_d2, \"hv_ref2\", \"UF\")\n",
    "# line_plot_average(performance_indicators_d2, \"hv_ref1\", \"MACO\")\n",
    "# line_plot_average(performance_indicators_d2, \"hv_ref2\", \"MACO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
